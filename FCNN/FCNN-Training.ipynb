{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install focal-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "from focal_loss import BinaryFocalLoss\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def pT_classes(x):\n",
    "    if x<=25:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df = pd.read_csv('../input/cmsdata/CMS_trigger.csv').drop(columns=['Unnamed: 0'])\n",
    "df['No. of non-hits'] = df[['Mask_'+str(i) for i in range(12)]].sum(axis = 1)\n",
    "df = df[df['No. of non-hits']<9].reset_index(drop=True)\n",
    "df['1/pT'] = df['q/pt'].abs()\n",
    "df['pT'] = 1/df['1/pT']\n",
    "df['pT_classes'] = df['pT'].apply(pT_classes)\n",
    "\n",
    "features = ['Phi_'+str(i) for i in range(12)] + ['Theta_'+str(i) for i in range(12)]\n",
    "labels_1 = ['1/pT']\n",
    "labels_2 = ['BendingAngle_'+str(i) for i in [0,1,9,10,11]]\n",
    "labels_3 = ['pT_classes']\n",
    "labels_4 = ['PatternStraightness']\n",
    "masks = ['Mask_'+str(i) for i in range(12)]\n",
    "\n",
    "scaler_1 = StandardScaler()\n",
    "df[features] = scaler_1.fit_transform(df[features])\n",
    "df[features] = df[features].fillna(0)\n",
    "\n",
    "scaler_2 = MinMaxScaler()\n",
    "df[labels_2] = scaler_2.fit_transform(df[labels_2])\n",
    "df[labels_2] = df[labels_2].fillna(0)\n",
    "\n",
    "scaler_3 = MinMaxScaler()\n",
    "df[labels_4] = scaler_3.fit_transform(df[labels_4])\n",
    "df[labels_4] = df[labels_4].fillna(0)\n",
    "\n",
    "df = df.sample(frac = 1, random_state = 242).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_list = list(range(len(df)))\n",
    "random.Random(242).shuffle(shuffled_list)\n",
    "shuffled_list = np.array_split(np.array(shuffled_list), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOF_preds = pd.DataFrame()\n",
    "OOF_preds['row'] = []\n",
    "OOF_preds['true_value'] = []\n",
    "OOF_preds['preds'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCNN(X_train, Y1_train, Y2_train, Y3_train, Y4_train):\n",
    "    p = 0.1\n",
    "    I = Input(shape=(36))\n",
    "    x = Dense(1024,activation='relu')(I)\n",
    "    x = BatchNormalization()(x)\n",
    "#     x = Dropout(p)(x)\n",
    "    x = Dense(128,activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#     x = Dropout(p)(x)\n",
    "    x_ = Dense(128,activation='relu')(x)\n",
    "    x = x + x_ \n",
    "    x = BatchNormalization()(x)\n",
    "#     x = Dropout(p)(x)\n",
    "    x1 = Dense(128,activation='relu')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x2 = Dense(128,activation='relu')(x)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x3 = Dense(128,activation='relu')(x)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x4 = Dense(128,activation='relu')(x)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    O1 = Dense(1,activation='sigmoid')(x1)\n",
    "    O2 = Dense(5,activation='sigmoid')(x2)\n",
    "    O3 = Dense(1,activation='sigmoid')(x3)\n",
    "    O4 = Dense(1,activation='sigmoid')(x4)\n",
    "    model = Model(inputs=I, outputs=[O1,O2,O3,O4])\n",
    "\n",
    "    batch_size=128\n",
    "    path = \"model.h5\"\n",
    "\n",
    "    checkpoint = ModelCheckpoint(path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    early_stop = EarlyStopping(monitor='val_loss',patience=10,verbose=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=2,verbose=True)\n",
    "\n",
    "    model.compile(optimizer = 'adam', loss=['mse','mse',BinaryFocalLoss(gamma=4),'mse'])\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(x=X_train, y=[Y1_train,Y2_train,Y3_train,Y4_train], batch_size=batch_size, epochs=5, verbose=0, validation_split=0.2, callbacks=[checkpoint,early_stop,reduce_lr])\n",
    "    \n",
    "    k = sorted(list(history.history.keys()))\n",
    "    plt.plot(history.history[k[4]])\n",
    "    plt.plot(history.history[k[10]])\n",
    "    plt.legend(['Total loss','Val loss'])\n",
    "    plt.show()\n",
    "    plt.plot(history.history[k[0]])\n",
    "    plt.plot(history.history[k[6]])\n",
    "    plt.legend(['Momentum MSE','Val Momentum MSE'])\n",
    "    plt.show()\n",
    "    plt.plot(history.history[k[1]])\n",
    "    plt.plot(history.history[k[7]])\n",
    "    plt.legend(['Bending Angle MSE','Val Bending Angle MSE'])\n",
    "    plt.show()\n",
    "    plt.plot(history.history[k[2]])\n",
    "    plt.plot(history.history[k[8]])\n",
    "    plt.legend(['Focal loss','Val Focal loss'])\n",
    "    plt.show()\n",
    "    plt.plot(history.history[k[3]])\n",
    "    plt.plot(history.history[k[9]])\n",
    "    plt.legend(['Pattern Straightness MSE','Val Pattern Straightness MSE'])\n",
    "    plt.show()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    X_train = df[features+masks].iloc[np.concatenate([shuffled_list[j] for j in range(10) if j not in (i,100)])]\n",
    "    Y1_train = df[labels_1].iloc[np.concatenate([shuffled_list[j] for j in range(10) if j not in (i,100)])]\n",
    "    Y2_train = df[labels_2].iloc[np.concatenate([shuffled_list[j] for j in range(10) if j not in (i,100)])]\n",
    "    Y3_train = df[labels_3].astype('float32').iloc[np.concatenate([shuffled_list[j] for j in range(10) if j not in (i,100)])]\n",
    "    Y4_train = df[labels_4].iloc[np.concatenate([shuffled_list[j] for j in range(10) if j not in (i,100)])]\n",
    "\n",
    "    X_test = df[features+masks].iloc[shuffled_list[i]]\n",
    "    Y1_test = df[labels_1].iloc[shuffled_list[i]]\n",
    "    Y2_test = df[labels_2].iloc[shuffled_list[i]]\n",
    "    Y3_test = df[labels_3].astype('float32').iloc[shuffled_list[i]]\n",
    "    Y4_test = df[labels_4].iloc[shuffled_list[i]]\n",
    "    \n",
    "    model = FCNN(X_train, Y1_train, Y2_train, Y3_train, Y4_train)\n",
    "    \n",
    "    P = model.predict(X_test)\n",
    "    \n",
    "    test_preds = P[0].reshape((len(X_test)))\n",
    "    \n",
    "    OOF_preds_ = pd.DataFrame()\n",
    "    OOF_preds_['row'] = shuffled_list[i]\n",
    "    OOF_preds_['true_value'] = Y1_test['1/pT'].values\n",
    "    OOF_preds_['preds'] = test_preds\n",
    "    OOF_preds = pd.concat([OOF_preds,OOF_preds_],axis = 0).reset_index(drop = True)\n",
    "    \n",
    "    print(classification_report(Y3_test.to_numpy().reshape((len(Y3_test))),np.array(P[2].reshape((len(Y3_test)))>0.5)*1))\n",
    "    print(confusion_matrix(Y3_test.to_numpy().reshape((len(Y3_test))),np.array(P[2].reshape((len(Y3_test)))>0.5)*1))\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOF_preds = OOF_preds.sort_values(by = 'row').reset_index(drop = True)\n",
    "OOF_preds.to_csv('OOF_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
